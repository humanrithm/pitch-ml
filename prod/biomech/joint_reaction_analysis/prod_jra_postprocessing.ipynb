{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a487ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "from connections import AWS\n",
    "from biomech.algorithms import butter_lowpass_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c07032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AWS]: Port 5433 is free.\n",
      "[AWS]: Connected to RDS endpoint.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" INITIALIZE AWS CONNECTION \"\"\"\n",
    "aws_connection = AWS()\n",
    "aws_connection.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09c526",
   "metadata": {},
   "source": [
    "$\\textbf{OpenSim Joint Reaction Analysis: Postprocessing}$\n",
    "\n",
    "- Aggregate all results files\n",
    "- Process results by computing normalized time, storing as dataframe, etc.\n",
    "- Evaluate peaks for each trial & inspect for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5411675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all subject info\n",
    "subject_info = aws_connection.load_subject_info()\n",
    "\n",
    "# load all (filtered) JRA files --> 3,650 total\n",
    "s3_objects = aws_connection.list_s3_objects(prefix='biomechanics/subjects/')\n",
    "jra_files = [obj for obj in s3_objects if obj.endswith('.sto') and 'jra_results' in obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53c59b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create normalized time column\n",
    "def compute_normalized_time(\n",
    "        data: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    # create normalized time\n",
    "    if 'normalized_time' not in data.columns:\n",
    "        data.insert(\n",
    "            0, \n",
    "            'normalized_time', \n",
    "            data['time'].transform(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "        )\n",
    "\n",
    "    return data\n",
    "\n",
    "# evalute peak value\n",
    "def evaluate_peak_jra_values(\n",
    "        data: pd.DataFrame,\n",
    "        peak_col: str \n",
    ") -> dict:\n",
    "    data_max = data[peak_col].max()\n",
    "    data_min = data[peak_col].min()\n",
    "\n",
    "    if data_max > abs(data_min):\n",
    "        return {\n",
    "            'subject_id': int(data['subject_id'].unique()[0]),\n",
    "            'study_id': data['study_id'].unique()[0],\n",
    "            'throwing_hand': data['throws'].unique()[0],\n",
    "            'peak_value': data_max,                                         # this can be used to find joint angles at peak\n",
    "            'peak_idx': data[peak_col].idxmax(),\n",
    "            'peak_was_negative': 0\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'subject_id': int(data['subject_id'].unique()[0]),\n",
    "            'study_id': data['study_id'].unique()[0],\n",
    "            'throwing_hand': data['throws'].unique()[0],\n",
    "            'peak_value': abs(data_min),\n",
    "            'peak_idx': data[peak_col].idxmin(),                            # this can be used to find joint angles at peak\n",
    "            'peak_was_negative': 1\n",
    "        }\n",
    "    \n",
    "# inspect subject results for outliers\n",
    "def inspect_subject_results(\n",
    "        data: pd.DataFrame,\n",
    "        peak_label: str = 'peak_value'\n",
    ") -> pd.DataFrame:\n",
    "    # get peak value mean and standard deviation\n",
    "        # NOTE: using median for mean to be more robust to outliers\n",
    "    subject_avg = data[peak_label].median()\n",
    "    subject_std = data[peak_label].std()\n",
    "\n",
    "    # add `outlier_flag` column\n",
    "    data['outlier_flag'] = 0\n",
    "\n",
    "    # iterate through rows to check for outliers\n",
    "    for idx, values in data.iterrows():\n",
    "        # update outlier flag if peak value is more than 2 standard deviations from the mean\n",
    "            # NOTE: using median for mean to be more robust to outliers\n",
    "        if (values['peak_value'] > subject_avg + 1.96 * subject_std) or (values['peak_value'] < subject_avg - 1.96 * subject_std):\n",
    "            data.at[idx, 'outlier_flag'] = 1\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28812eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing subject 2609.\n",
      "Finished processing subject 2610.\n",
      "Finished processing subject 2611.\n",
      "Finished processing subject 2612.\n",
      "Finished processing subject 2613.\n",
      "Finished processing subject 2614.\n",
      "Finished processing subject 2616.\n",
      "Finished processing subject 2618.\n",
      "Finished processing subject 2619.\n",
      "Finished processing subject 2621.\n",
      "Finished processing subject 2622.\n",
      "Finished processing subject 2623.\n",
      "Finished processing subject 2624.\n",
      "Finished processing subject 2625.\n",
      "Finished processing subject 2627.\n",
      "Finished processing subject 2628.\n",
      "Finished processing subject 2629.\n",
      "Finished processing subject 2630.\n",
      "Finished processing subject 2631.\n",
      "Finished processing subject 2633.\n",
      "Finished processing subject 2634.\n",
      "Finished processing subject 2635.\n",
      "Finished processing subject 2636.\n",
      "Finished processing subject 2638.\n",
      "Finished processing subject 2639.\n",
      "Finished processing subject 2640.\n",
      "Finished processing subject 2641.\n",
      "Finished processing subject 2642.\n",
      "Finished processing subject 2643.\n",
      "Finished processing subject 2644.\n",
      "Finished processing subject 2645.\n",
      "Finished processing subject 2646.\n",
      "Finished processing subject 2647.\n",
      "Finished processing subject 2648.\n",
      "Finished processing subject 2649.\n",
      "Finished processing subject 2650.\n",
      "Finished processing subject 2651.\n",
      "Finished processing subject 2652.\n",
      "Finished processing subject 2653.\n",
      "Finished processing subject 2654.\n",
      "Finished processing subject 2655.\n",
      "Finished processing subject 2657.\n",
      "Finished processing subject 2658.\n",
      "Finished processing subject 2659.\n",
      "Finished processing subject 2660.\n",
      "Finished processing subject 2661.\n",
      "Finished processing subject 2662.\n",
      "Finished processing subject 2664.\n",
      "Finished processing subject 2665.\n",
      "Finished processing subject 2666.\n",
      "Finished processing subject 2667.\n",
      "Finished processing subject 2668.\n",
      "Finished processing subject 2669.\n",
      "Finished processing subject 2670.\n",
      "Finished processing subject 2671.\n",
      "Finished processing subject 2672.\n",
      "Finished processing subject 2673.\n",
      "Finished processing subject 2674.\n",
      "Finished processing subject 2675.\n",
      "Finished processing subject 2676.\n",
      "Finished processing subject 2680.\n",
      "Finished processing subject 2681.\n",
      "Finished processing subject 2726.\n",
      "Finished processing subject 2727.\n",
      "Finished processing subject 2728.\n",
      "Finished processing subject 2745.\n",
      "Finished processing subject 2746.\n",
      "Finished processing subject 2747.\n",
      "Finished processing subject 2748.\n",
      "Finished processing subject 2749.\n",
      "Finished processing subject 2750.\n",
      "Finished processing subject 2751.\n",
      "Finished processing subject 2761.\n",
      "Finished processing subject 2762.\n",
      "Finished processing subject 2764.\n",
      "Finished processing subject 2765.\n",
      "Finished processing subject 2766.\n",
      "Finished processing subject 2767.\n",
      "Finished processing subject 2768.\n",
      "Finished processing subject 2941.\n",
      "Finished processing subject 2942.\n",
      "Finished processing subject 2943.\n",
      "Finished processing subject 2945.\n",
      "Finished processing subject 2946.\n",
      "Finished processing subject 2947.\n",
      "Finished processing subject 2948.\n",
      "Finished processing subject 2949.\n",
      "Finished processing subject 2950.\n",
      "Finished processing subject 2951.\n",
      "Finished processing subject 2952.\n",
      "Finished processing subject 2953.\n",
      "Finished processing subject 2954.\n",
      "Finished processing subject 2955.\n",
      "Finished processing subject 2956.\n",
      "Finished processing subject 2957.\n",
      "Finished processing subject 2958.\n",
      "Finished processing subject 2959.\n",
      "Finished processing subject 2961.\n",
      "Finished processing subject 2962.\n",
      "Finished processing subject 2964.\n",
      "Finished processing subject 2965.\n",
      "Finished processing subject 2966.\n",
      "Finished processing subject 2967.\n",
      "Finished processing subject 2968.\n",
      "Finished processing subject 2969.\n",
      "Finished processing subject 2970.\n",
      "Finished processing subject 2971.\n",
      "Finished processing subject 2972.\n",
      "Finished processing subject 2973.\n",
      "Finished processing subject 2974.\n",
      "Finished processing subject 2975.\n",
      "Finished processing subject 2976.\n",
      "Finished processing subject 2977.\n",
      "Finished processing subject 2978.\n",
      "Finished processing subject 2979.\n",
      "Finished processing subject 2980.\n",
      "Finished processing subject 2981.\n",
      "Finished processing subject 2982.\n",
      "Finished processing subject 2983.\n",
      "Finished processing subject 2984.\n",
      "Finished processing subject 2985.\n",
      "Finished processing subject 2986.\n",
      "Finished processing subject 2987.\n",
      "Finished processing subject 2988.\n",
      "Finished processing subject 2989.\n",
      "Finished processing subject 2991.\n",
      "Finished processing subject 2992.\n",
      "Finished processing subject 2993.\n",
      "Finished processing subject 2994.\n",
      "Finished processing subject 2996.\n",
      "Finished processing subject 2997.\n",
      "Finished processing subject 2998.\n",
      "Finished processing subject 3023.\n",
      "Finished processing subject 3025.\n",
      "Finished processing subject 3027.\n",
      "Finished processing subject 3028.\n",
      "Finished processing subject 3032.\n",
      "Finished processing subject 3033.\n",
      "Finished processing subject 3034.\n",
      "Finished processing subject 3035.\n",
      "Finished processing subject 3036.\n",
      "Finished processing subject 3039.\n",
      "Finished processing subject 3040.\n",
      "Finished processing subject 3041.\n",
      "Finished processing subject 3042.\n",
      "Finished processing subject 3043.\n",
      "Finished processing subject 3045.\n",
      "Finished processing subject 3047.\n",
      "Finished processing subject 3050.\n",
      "Finished processing subject 3051.\n",
      "Finished processing subject 3052.\n",
      "Finished processing subject 3053.\n",
      "Finished processing subject 3054.\n",
      "Finished processing subject 3055.\n",
      "Finished processing subject 3056.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 12:04:24,186| ERROR   | Socket exception: Connection reset by peer (54)\n"
     ]
    }
   ],
   "source": [
    "# initialize JRA peak results\n",
    "error_log = []\n",
    "all_subject_results = []\n",
    "\n",
    "# iterate through subjects\n",
    "    # NOTE: doing this to streamline outlier detection\n",
    "for subject_id in subject_info['subject_id'].unique():\n",
    "\n",
    "    print(f'Processing subject {subject_id}...', end='\\r', flush=True)\n",
    "    \n",
    "    # filter JRA files for this subject\n",
    "    subject_jra_files = [f for f in jra_files if str(subject_id) in f]\n",
    "\n",
    "    # initialize list of peaks\n",
    "    subject_jra_peaks = []\n",
    "    \n",
    "    # iterate through subject files\n",
    "    for f in subject_jra_files:\n",
    "        \n",
    "        try:\n",
    "            # extract subject ID, study ID, and throwing hand\n",
    "            study_id = f.split('/')[-1].split('_jra')[0]\n",
    "            subject_id = study_id.split('_')[0]\n",
    "            throwing_hand = subject_info.loc[subject_info['subject_id'] == int(subject_id), 'throws'].values[0]\n",
    "\n",
    "            # specify elbow moment columns\n",
    "                # NOTE: this is throwing arm dependent\n",
    "            if throwing_hand == 'right':\n",
    "                ELBOW_MOMENT_COLS = [\n",
    "                    'elbow_r_on_ulna_r_in_ulna_r_mx', \n",
    "                    'elbow_r_on_ulna_r_in_ulna_r_my', \n",
    "                    'elbow_r_on_ulna_r_in_ulna_r_mz'\n",
    "                ]\n",
    "                PEAK_COL = 'elbow_r_on_ulna_r_in_ulna_r_mx'\n",
    "            else:\n",
    "                ELBOW_MOMENT_COLS = [\n",
    "                    'elbow_l_on_ulna_l_in_ulna_l_mx', \n",
    "                    'elbow_l_on_ulna_l_in_ulna_l_my', \n",
    "                    'elbow_l_on_ulna_l_in_ulna_l_mz'\n",
    "                ]\n",
    "                PEAK_COL = 'elbow_l_on_ulna_l_in_ulna_l_mx'\n",
    "            \n",
    "            # read data from S3\n",
    "            jra_bytes = aws_connection.load_s3_object(f, return_info=False)\n",
    "            jra_data = pd.read_csv(\n",
    "                io.BytesIO(jra_bytes), \n",
    "                sep='\\s+', \n",
    "                skiprows=11\n",
    "            )\n",
    "            \n",
    "            # trim to elbow moment columns, then normalize time\n",
    "            jra_data = jra_data[['time'] + ELBOW_MOMENT_COLS]\n",
    "            jra_data_nt = compute_normalized_time(jra_data)\n",
    "\n",
    "            # insert subject and study ID\n",
    "            jra_data_nt.insert(0, 'subject_id', int(subject_id))\n",
    "            jra_data_nt.insert(1, 'study_id', study_id)\n",
    "            jra_data_nt.insert(2, 'throws', throwing_hand)\n",
    "\n",
    "            # get peak summary\n",
    "            peak_summary = evaluate_peak_jra_values(jra_data_nt, PEAK_COL)\n",
    "            subject_jra_peaks.append(peak_summary)\n",
    "\n",
    "        except Exception as e:\n",
    "            # log error\n",
    "            error_log.append({\n",
    "                'study_id': study_id,\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "            print(f'Error processing {f}: {e}')\n",
    "            \n",
    "            continue\n",
    "\n",
    "    # create dataframe of subject peaks --> inspect for outliers\n",
    "        # NOTE: outliers are flagged, not removed\n",
    "    if len(subject_jra_peaks) > 0:\n",
    "        subject_jra_peaks_df = pd.DataFrame(subject_jra_peaks)\n",
    "        subject_jra_clean = inspect_subject_results(subject_jra_peaks_df)\n",
    "        \n",
    "        # append subject results to full list\n",
    "        all_subject_results.append(subject_jra_clean)\n",
    "\n",
    "    print(f'Finished processing subject {subject_id}.')\n",
    "\n",
    "# concatenate all subject results\n",
    "all_subject_results_df = pd.concat(all_subject_results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a29ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocessing --> ~58 Â± 22 Nm \n",
    "all_subject_results_df.loc[all_subject_results_df['peak_value'] < 10, 'outlier_flag'] = 1\n",
    "all_subject_results_df.loc[all_subject_results_df['peak_value'] > 200, 'outlier_flag'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dcc44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AWS]: Uploaded object to s3://pitch-ml/subjects/summary/results_jra.csv\n",
      "[AWS]: Uploaded object to s3://pitch-ml/subjects/summary/results_jra_outliers.csv\n"
     ]
    }
   ],
   "source": [
    "# write full subject results to S3 (outliers separated; 247 outliers total, )\n",
    "aws_connection.upload_to_s3(\n",
    "    all_subject_results_df[all_subject_results_df['outlier_flag'] == 0].reset_index(drop=True).to_csv(index=False),\n",
    "    'subjects/summary/results_jra.csv'\n",
    ")\n",
    "aws_connection.upload_to_s3(\n",
    "    all_subject_results_df[all_subject_results_df['outlier_flag'] == 1].reset_index(drop=True).to_csv(index=False),\n",
    "    'subjects/summary/results_jra_outliers.csv'\n",
    ")\n",
    "\n",
    "# write error log to S3 (if applicable)\n",
    "if error_log:\n",
    "    error_log_df = pd.DataFrame(error_log)\n",
    "    aws_connection.upload_to_s3(\n",
    "        error_log_df.to_csv(index=False),\n",
    "        'subjects/summary/error_log_jra.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985cc27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pitch_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
