{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from connections import AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Feature Importances}$\n",
    "\n",
    "Applies the permutation-based feature importance method to each subject-specific model to determine the most important ball flight features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AWS]: Port 5433 is free.\n",
      "[AWS]: Connected to RDS endpoint.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" INITIALIZE AWS CONNECTION \"\"\"\n",
    "aws_connection = AWS()\n",
    "aws_connection.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data w/ model predictions\n",
    "model_data = aws_connection.load_s3_object('biomechanics/ml/modeling_datasets/model_dev_raw.csv')\n",
    "model_preds = aws_connection.load_s3_object('biomechanics/ml/modeling_summary/model_preds.csv')\n",
    "\n",
    "# load subject info\n",
    "subject_info = aws_connection.load_subject_info()\n",
    "subject_ids = subject_info['subject_id'].unique()\n",
    "\n",
    "# instantiate subject model storage\n",
    "with open('all_subject_models.pkl', 'rb') as f:\n",
    "    models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through subject IDs and load models\n",
    "for subject_id in subject_ids:\n",
    "    # check if model already exists\n",
    "    if subject_id in models.keys():\n",
    "        continue\n",
    "    \n",
    "    # set model path\n",
    "    model_path = f'biomechanics/subjects/{subject_id}/ml/model_summary.pkl'\n",
    "    \n",
    "    # check if model exists in S3\n",
    "    try:\n",
    "        aws_connection.s3.download_file(\n",
    "            aws_connection.bucket_name, \n",
    "            model_path,\n",
    "            f'subject_model.pkl'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f'No model found for subject {subject_id}. Skipping...')\n",
    "        continue\n",
    "\n",
    "    with open('subject_model.pkl', 'rb') as f:\n",
    "        model_summary = pickle.load(f)\n",
    "        models[subject_id] = model_summary['baseline_rf']['model']\n",
    "\n",
    "    print(f'Loaded model for subject {subject_id}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to all subject models\n",
    "with open('all_subject_models.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Permutations}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all ball flight features \n",
    "model_features = ['vra', 'hra', 'rel_side', 'rel_ht', 'spin_rate', 'spin_axis', 'rel_speed', 'ax0', 'ay0', 'az0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing importances for feature: vra.\n",
      "Computing importances for feature: hra.\n",
      "Computing importances for feature: rel_side.\n",
      "Computing importances for feature: rel_ht.\n",
      "Computing importances for feature: spin_rate.\n",
      "Computing importances for feature: spin_axis.\n",
      "Computing importances for feature: rel_speed.\n",
      "Computing importances for feature: ax0.\n",
      "Computing importances for feature: ay0.\n",
      "Computing importances for feature: az0.\n"
     ]
    }
   ],
   "source": [
    "# initialize importances, model features\n",
    "importances = {}\n",
    "num_pitches = {}\n",
    "model_features = [\n",
    "    'vra', 'hra', \n",
    "    'rel_side', 'rel_ht', \n",
    "    'spin_rate', 'spin_axis', \n",
    "    'rel_speed', 'ax0', 'ay0', 'az0'\n",
    "]\n",
    "\n",
    "# iterate through features\n",
    "for f in model_features:\n",
    "    # get data, initialize importance\n",
    "    copy = model_data.merge(subject_info, on='subject_id').copy()\n",
    "    importances[f] = []\n",
    "    num_pitches[f] = []\n",
    "\n",
    "    print(f'Computing importances for feature: {f}.')\n",
    "\n",
    "    # iterate through subject IDs\n",
    "    for subject_id in models.keys():\n",
    "        # get subject data & model\n",
    "        subject_data = copy[copy['subject_id'] == subject_id]\n",
    "        num_pitches[f].append(subject_data.shape[0])\n",
    "        peak_elbow_moment_rf = models[subject_id]\n",
    "    \n",
    "        # get orig. preds\n",
    "        pred_orig = peak_elbow_moment_rf.predict(subject_data[peak_elbow_moment_rf.feature_names_in_])\n",
    "        pred_orig_scaled = pred_orig * subject_data['mass'] * subject_data['height'] * 9.81\n",
    "\n",
    "        # compute orig. rmse\n",
    "        rmse_orig = root_mean_squared_error(\n",
    "            y_true=subject_data['peak_value'],\n",
    "            y_pred=pred_orig_scaled\n",
    "        )\n",
    "\n",
    "        # permute/shuffle 100 times\n",
    "        rmse_permuted = []\n",
    "        for i in range(100):\n",
    "            # permute feature\n",
    "            subject_data[f] = subject_data[f].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "            # get new preds\n",
    "            pred_permuted = peak_elbow_moment_rf.predict(subject_data[peak_elbow_moment_rf.feature_names_in_])\n",
    "            pred_permuted_scaled = pred_permuted * subject_data['mass'] * subject_data['height'] * 9.81\n",
    "\n",
    "            # compute permuted rmse\n",
    "            new_error = root_mean_squared_error(\n",
    "                y_true=subject_data['peak_value'],\n",
    "                y_pred=pred_permuted_scaled\n",
    "            )\n",
    "            rmse_permuted.append(new_error - rmse_orig)\n",
    "\n",
    "        # compute average delta rmse\n",
    "        delta_rmse = np.mean(rmse_permuted)\n",
    "        importances[f].append(delta_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute weighted average of importances based on number of pitches --> relative importance\n",
    "wtd_importances = {}\n",
    "for f in importances.keys():\n",
    "    if np.array(num_pitches[f]).sum() == 0:\n",
    "        wtd_importances[f] = 0\n",
    "    else:\n",
    "        wtd_importances[f] = np.average(importances[f], weights=num_pitches[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe w/ importances\n",
    "ft_importances = pd.DataFrame([wtd_importances]).T.rename(columns={0: 'delta_rmse'})\n",
    "\n",
    "# compute normalized importances\n",
    "ft_importances['relative_importance'] = ft_importances['delta_rmse'] / ft_importances['delta_rmse'].sum()\n",
    "ft_importances.sort_values(by='relative_importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_rmse</th>\n",
       "      <th>relative_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rel_speed</th>\n",
       "      <td>9.150737</td>\n",
       "      <td>0.243871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rel_side</th>\n",
       "      <td>7.839572</td>\n",
       "      <td>0.208928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rel_ht</th>\n",
       "      <td>4.746251</td>\n",
       "      <td>0.126490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spin_rate</th>\n",
       "      <td>4.340058</td>\n",
       "      <td>0.115664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spin_axis</th>\n",
       "      <td>3.990498</td>\n",
       "      <td>0.106348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>az0</th>\n",
       "      <td>3.382758</td>\n",
       "      <td>0.090152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ax0</th>\n",
       "      <td>2.077948</td>\n",
       "      <td>0.055378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ay0</th>\n",
       "      <td>1.995034</td>\n",
       "      <td>0.053169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vra</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hra</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           delta_rmse  relative_importance\n",
       "rel_speed    9.150737             0.243871\n",
       "rel_side     7.839572             0.208928\n",
       "rel_ht       4.746251             0.126490\n",
       "spin_rate    4.340058             0.115664\n",
       "spin_axis    3.990498             0.106348\n",
       "az0          3.382758             0.090152\n",
       "ax0          2.077948             0.055378\n",
       "ay0          1.995034             0.053169\n",
       "vra          0.000000             0.000000\n",
       "hra          0.000000             0.000000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Close AWS Connections}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AWS]: No active connection to close.\n"
     ]
    }
   ],
   "source": [
    "aws_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pitch_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
