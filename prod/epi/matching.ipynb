{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb917364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from connections import AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd0de54",
   "metadata": {},
   "source": [
    "$\\textbf{Epidemiology: Pitcher Matching}$\n",
    "\n",
    "Attempts to find the best possible non-injured match for each pitcher based on: \n",
    "- `height`\n",
    "- `mass`\n",
    "- `number of pitches thrown`\n",
    "- `time interval`\n",
    "\n",
    "The last is the most difficult because it requires re-computing the number of pitches thrown between dates based on each injured pitcher. A manual distance-based algorithm is used to identify matching pitchers, and the closest match is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7cd1a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AWS]: Port 5433 is free.\n",
      "[AWS]: Connected to RDS endpoint.\n"
     ]
    }
   ],
   "source": [
    "# set up AWS connection\n",
    "aws = AWS()\n",
    "aws.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5a7f6f",
   "metadata": {},
   "source": [
    "$\\textbf{Data Loading}$\n",
    "\n",
    "- Cohorts\n",
    "- Ball Tracking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d18b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.ball_tracking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5aac507",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Injured Cohort \"\"\"\n",
    "# load cohort metadata (mass, height, and pitches prior to injury)\n",
    "cohort = aws.load_s3_object('epidemiology/cohorts/injured/pitcher_info/pitchers_0825.csv')\n",
    "cohort_metadata = aws.load_s3_object('epidemiology/cohorts/injured/pitcher_info/pitchers_metadata.csv')\n",
    "cohort_injured = cohort_metadata.rename(columns={'mlbam_id': 'mlbamid'}).merge(cohort[['mlbamid', 'injury_date']], on='mlbamid', how='left')\n",
    "\n",
    "# add season to injured pitchers\n",
    "cohort_injured['injury_date'] = pd.to_datetime(cohort_injured['injury_date'], errors='coerce')\n",
    "cohort_injured['season'] = cohort_injured['injury_date'].apply(lambda x: x.year if pd.notnull(x) else None)\n",
    "\n",
    "# created injured flag (:= 1)\n",
    "cohort_injured['injured'] = 1\n",
    "\n",
    "# update pitches thrown column\n",
    "cohort_injured.rename(columns={'pitches_prior_to_injury': 'pitches_thrown'}, inplace=True)\n",
    "\n",
    "\"\"\" Non-injured Cohort \"\"\"\n",
    "cohort_noninjured = aws.load_s3_object('epidemiology/cohorts/noninjured/pitcher_info/pitchers_0825.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Ball Tracking Data \"\"\"\n",
    "# all ball tracking data w/ model predictions\n",
    "    # NOTE: some duplicates exist\n",
    "raw_data = aws.load_s3_object('epidemiology/ml/datasets/full/model_application_data.csv')\n",
    "model_preds = aws.load_s3_object('epidemiology/ml/datasets/preds/model_application.csv')\n",
    "model_preds.drop_duplicates(subset=['pitcher', 'game_date', 'pred_peak_evt'], inplace=True)\n",
    "model_preds['season'] = model_preds['game_date'].str[:4].astype(int)                                # add season to model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73df43a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pitch labels\n",
    "inj_bt_labels = aws.load_s3_object('epidemiology/ml/datasets/full/injured_pitch_labels.csv')\n",
    "noninj_bt_labels = aws.load_s3_object('epidemiology/ml/datasets/full/noninjured_pitch_labels.csv')\n",
    "\n",
    "# map pitch types to condensed groups\n",
    "pt_map = {\n",
    "    'FF': 'FB', 'FT': 'FB', 'FC': 'FB', 'FS': 'FB', 'SI': 'FB',\n",
    "    'CU': 'CB', 'KC': 'CB', 'SL': 'SL', 'KN': 'KN', 'SV': 'CB', 'ST': 'SL', 'SC': 'CB',\n",
    "    'CH': 'CH', 'FO': 'CH', 'EP': 'CH'\n",
    "}\n",
    "inj_bt_labels['pitch_type'] = inj_bt_labels['pitch_type'].map(pt_map).dropna()\n",
    "noninj_bt_labels['pitch_type'] = noninj_bt_labels['pitch_type'].map(pt_map).dropna()\n",
    "\n",
    "# aggregate pitch counts & pivot to wide for matching\n",
    "inj_pt_counts = pivot_pitch_labels(inj_bt_labels)\n",
    "noninj_pt_counts = pivot_pitch_labels(noninj_bt_labels)\n",
    "\n",
    "# rename pitcher column to mlbamid\n",
    "inj_pt_counts.rename(columns={'pitcher': 'mlbamid'}, inplace=True)\n",
    "noninj_pt_counts.rename(columns={'pitcher': 'mlbamid'}, inplace=True)\n",
    "\n",
    "# upload counts to S3\n",
    "aws.upload_to_s3(inj_pt_counts, 'epidemiology/ml/datasets/full/injured_pitch_counts.csv')\n",
    "aws.upload_to_s3(noninj_pt_counts, 'epidemiology/ml/datasets/full/noninjured_pitch_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee65c3",
   "metadata": {},
   "source": [
    "$\\textbf{Matching}$\n",
    "\n",
    "Scales based on matching criteria: __height, mass, pitches thrown, pitch type usage__.\n",
    "- __Note__: Pitches thrown is based on the number of pitches w/ model predictions v. the number of counted pitches\n",
    "    - Sometimes there is a slight discrepancy... this does seem to preseve more matches, though, likely because of Spring Training data\n",
    "- Pitches thrown are counted between the injured pitcher's first and last pitch\n",
    "- Only pitchers throwing Â±10% of the injured pitcher's total pitches are considered\n",
    "\n",
    "Euclidean distance is used to compute the matching criteria, selecting the minimum for each pitcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "178683d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from services.matching import compute_matching_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7ba83e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute scaler for matching criteria\n",
    "matching_cols = ['mlbamid', 'season', 'height', 'mass', 'pitches_thrown']\n",
    "\n",
    "# create cohort w/ matching data\n",
    "cohort_injured_counts = cohort_injured.merge(inj_pt_counts, on=['mlbamid', 'season'], how='inner')\n",
    "cohort_noninjured_counts = cohort_noninjured.merge(noninj_pt_counts, on=['mlbamid', 'season'], how='inner')\n",
    "cohort_matching_data = pd.concat([cohort_injured_counts, cohort_noninjured_counts])\n",
    "\n",
    "# create scalers for each year\n",
    "matching_scalers = {}\n",
    "for s in [i for i in range(2015, 2026)]:\n",
    "    # filter data for the current season, fit scaler\n",
    "    season_data = cohort_matching_data[cohort_matching_data['season'] == s][matching_cols + [col for col in inj_pt_counts.columns if col not in ['mlbamid', 'season']]]\n",
    "    scaler = StandardScaler().fit(season_data[['height', 'mass', 'pitches_thrown'] + [col for col in inj_pt_counts.columns if col not in ['mlbamid', 'season']]])\n",
    "    \n",
    "    # save to dictionary\n",
    "    matching_scalers[s] = scaler\n",
    "\n",
    "# save to disc\n",
    "with open('models/matching_scalers.pkl', 'wb') as f:\n",
    "    pickle.dump(matching_scalers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7178206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through injured pitchers\n",
    "    # check if pitcher has pitches from season of injury (if not --> pass) \n",
    "    # get all pitches in date range, check for non-injured pitchers with pitches in date range --> compute matching info\n",
    "matches = []\n",
    "for idx, row in cohort_injured_counts.iterrows():\n",
    "    \n",
    "    # extract pitcher, season\n",
    "    pitcher = row['mlbamid']\n",
    "    season = row['season']\n",
    "    \n",
    "    # get injured pitcher's ball tracking data, season(s) w/ pitches\n",
    "    inj_data_season = model_preds[\n",
    "        (model_preds['pitcher'].isin(list(cohort_injured['mlbamid']))) & \n",
    "        (model_preds['season'] == season)\n",
    "    ].copy()\n",
    "    pitcher_bt = inj_data_season[(inj_data_season['pitcher'] == pitcher) & (inj_data_season['season'] == season)].sort_values('game_date')\n",
    "    seasons_pitched = get_season_from_date(pitcher_bt['game_date'])\n",
    "\n",
    "    # skip if pitcher has no pitches in season of injury\n",
    "    if season not in seasons_pitched or pitcher_bt.empty:\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        # get all pitcher metadata\n",
    "        inj_ht = row['height']\n",
    "        inj_mass = row['mass']\n",
    "        inj_pitches = pitcher_bt.shape[0]\n",
    "        inj_first_pitch_date = pitcher_bt['game_date'].min()\n",
    "        inj_last_pitch_date = pitcher_bt['game_date'].max()\n",
    "        inj_outing_count = pitcher_bt['game_date'].nunique()                                    # for matching based on no. of outings\n",
    "\n",
    "        # get non-injured pitcher ball tracking data from season of injury\n",
    "        noninj_data_season = model_preds[\n",
    "            (model_preds['pitcher'].isin(list(cohort_noninjured['mlbamid']))) & \n",
    "            (model_preds['season'] == season)\n",
    "        ].copy()\n",
    "\n",
    "        # get all pitches btw inj_first_pitch_date & inj_last_pitch_date\n",
    "            # then get pitch counts for each non-injured pitcher\n",
    "        noninj_data_season = noninj_data_season[\n",
    "            (noninj_data_season['game_date'] >= inj_first_pitch_date) & \n",
    "            (noninj_data_season['game_date'] <= inj_last_pitch_date)\n",
    "        ]\n",
    "\n",
    "        # get pitch counts & outing counts for non-injured pitchers in date range\n",
    "        noninj_pitch_counts = noninj_data_season.groupby(['pitcher', 'season']).size().reset_index(name='pitches_thrown_interval')\n",
    "        noninj_outing_counts = noninj_data_season.groupby(['pitcher', 'season'])['game_date'].nunique().reset_index(name='outings_interval')\n",
    "        noninj_counts = noninj_pitch_counts.merge(noninj_outing_counts, on=['pitcher', 'season'])\n",
    "        \n",
    "        # skip if no non-injured pitchers have pitches in date range (e.g., spring training injury)\n",
    "        if noninj_counts.empty:\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            # get eligible non-injured pitchers w/ pitches thrown during interval\n",
    "                # trim to matching columns, rename to match scaler\n",
    "                # NOTE: only pitchers within 20% of injured pitcher's pitches thrown are considered eligible\n",
    "            eligible_noninj = cohort_noninjured.merge(noninj_counts, left_on=['mlbamid', 'season'], right_on=['pitcher', 'season'], how='inner')\n",
    "            eligible_noninj = eligible_noninj[['season', 'mlbamid', 'height', 'mass', 'pitches_thrown_interval', 'outings_interval']].rename(columns={'pitches_thrown_interval': 'pitches_thrown'})\n",
    "\n",
    "            # NOTE (above): filter eligible non-injured pitchers to those within 10% of injured pitcher's pitches thrown\n",
    "                # after, join pitch counts\n",
    "            eligible_noninj_filt = eligible_noninj[\n",
    "                ((eligible_noninj['pitches_thrown'] >= 0.9 * inj_pitches) &\n",
    "                (eligible_noninj['pitches_thrown'] <= 1.1 * inj_pitches)) & \n",
    "                (abs(eligible_noninj['outings_interval'] - inj_outing_count) <= 2)    # within 1 outing of injured pitcher\n",
    "            ].reset_index(drop=True)\n",
    "            eligible_noninj_pitch_counts = eligible_noninj_filt.merge(noninj_pt_counts, on=['mlbamid', 'season'], how='inner')\n",
    "\n",
    "            # skip if no eligible non-injured pitchers\n",
    "            if eligible_noninj_filt.empty:\n",
    "                continue\n",
    "\n",
    "            # compute matching criteria\n",
    "            inj_pitcher_info = pd.DataFrame([{\n",
    "                'season': season,\n",
    "                'mlbamid': pitcher,\n",
    "                'height': inj_ht,\n",
    "                'mass': inj_mass,\n",
    "                'pitches_thrown': inj_pitches\n",
    "            }])\n",
    "            inj_pitcher_info = inj_pitcher_info.merge(inj_pt_counts, on=['mlbamid', 'season'], how='inner')\n",
    "\n",
    "            # scale matching criteria\n",
    "            season_scaler = matching_scalers[season]            # load scaler\n",
    "            inj_scaled = inj_pitcher_info.copy()\n",
    "            noninj_scaled = eligible_noninj_pitch_counts.copy()\n",
    "            inj_scaled[season_scaler.feature_names_in_] = season_scaler.transform(inj_pitcher_info[season_scaler.feature_names_in_])\n",
    "            noninj_scaled[season_scaler.feature_names_in_] = season_scaler.transform(eligible_noninj_pitch_counts[season_scaler.feature_names_in_])\n",
    "            \n",
    "            # get matching info\n",
    "            match_info = compute_matching_info(inj_scaled, noninj_scaled, season_scaler.feature_names_in_, metric='euclidean')\n",
    "            matched_pitcher = eligible_noninj_pitch_counts[eligible_noninj_pitch_counts['mlbamid'] == match_info['mlbamid_noninjured']]\n",
    "\n",
    "            # store differences btw matched pitchers (inj - noninj)\n",
    "            match_info['ht_diff'] = inj_ht - matched_pitcher['height'].values[0]\n",
    "            match_info['mass_diff'] = inj_mass - matched_pitcher['mass'].values[0]\n",
    "            match_info['pitches_thrown_diff'] = inj_pitches - matched_pitcher['pitches_thrown'].values[0]\n",
    "            match_info['outings_diff'] = inj_outing_count - matched_pitcher['outings_interval'].values[0]\n",
    "            \n",
    "            # update metadata & store\n",
    "            match_info['season'] = season\n",
    "            matches.append(match_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac4986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AWS]: Uploaded object to s3://pitch-ml/epidemiology/cohorts/injured/pitcher_info/matches_0825.csv\n"
     ]
    }
   ],
   "source": [
    "# create dataframe of matches, upload to S3\n",
    "    # avg diffs: \n",
    "    #   ht: 0.04 m \n",
    "    #   mass: 6.5 kg\n",
    "    #   pitches thrown = 26.6 (mean), 12 (median)\n",
    "    #   outings = 0.98\n",
    "matches_full = pd.DataFrame(matches).drop_duplicates()\n",
    "aws.upload_to_s3(matches_full, 'epidemiology/cohorts/injured/pitcher_info/matches_0825.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb28bf",
   "metadata": {},
   "source": [
    "$\\textbf{Close AWS Connection}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3f5e20a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AWS]: No active connection to close.\n"
     ]
    }
   ],
   "source": [
    "aws.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6be348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pitch_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
